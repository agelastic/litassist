# Analysis and extraction prompt templates
# Used for case facts analysis, chunk processing, and data extraction

analysis:
  # Base case facts prompt - just the case facts section
  # USED BY: caseplan.py - budget assessment mode
  # LOCATION: caseplan.py:145
  base_case_facts_prompt: |
    CASE FACTS:
    {facts_content}
  
  # Case facts prompt template with outcome and issues
  # USED BY: strategy.py - building base user prompt
  # LOCATION: strategy.py:267
  case_facts_prompt: |
    CASE FACTS:
    {facts_content}
    
    DESIRED OUTCOME:
    {outcome}
    
    IDENTIFIED LEGAL ISSUES:
    {legal_issues}

  # Strategy ranking prompt for case facts
  # USED BY: strategy.py - ranking all strategies
  # LOCATION: strategy.py:538
  strategy_ranking_prompt: |
    CASE FACTS:
    {facts_content}
    
    DESIRED OUTCOME:
    {outcome}
    
    AVAILABLE STRATEGIES:
    {strategies_list}
    
    Analyze all {strategy_count} strategies above and rank them by likelihood of success for achieving the specific outcome "{outcome}" given these case facts.
    
    Use the SAME criteria as brainstorm command's "most likely to succeed" analysis:
    - Legal merit and strength of legal foundation
    - Factual support from the case materials provided
    - Precedential strength and established legal principles
    - Likelihood of judicial acceptance in Australian courts
    
    Additional focus for this specific outcome:
    - Direct relevance to achieving "{outcome}"
    - Procedural feasibility for this specific result
    - Practical implementation steps available
    
    Output format:
    RANKING: [comma-separated list of strategy numbers in order of likelihood, e.g., "3,1,7,2"]
    REASONING: [brief explanation focusing on legal merit, factual support, precedential strength, and judicial likelihood for the top strategies]

  # Remaining strategies ranking prompt
  # USED BY: strategy.py - ranking strategies after most likely selected
  # LOCATION: strategy.py:451
  remaining_strategies_prompt: |
    CASE FACTS:
    {facts_content}
    
    DESIRED OUTCOME:
    {outcome}
    
    We have already selected {selected_count} 'most likely to succeed' strategies. Now rank these remaining strategies by likelihood of success for achieving "{outcome}":
    
    {remaining_strategies_list}
    
    Rank them using the same criteria: legal merit, factual support, precedential strength, and judicial likelihood for this specific outcome.
    
    Output format:
    RANKING: [comma-separated list of strategy numbers in order of likelihood, e.g., "2,1,4"]
    REASONING: [brief explanation for top selections]

  # Extraction base prompt
  # USED BY: extractfacts.py - lines 85-88 (single chunk extraction)
  # LOCATION: Base prompt for extracting facts under structured headings
  extraction:
    # USED BY: extractfacts.py - no documents provided
    # LOCATION: extractfacts.py:89
    base_prompt: "Extract under these headings (include all relevant details):\n{format_instructions}\n\n=== CONTENT TO EXTRACT ===\n{content}\n=== END CONTENT TO EXTRACT ==="
    # USED BY: extractfacts.py - processing document chunks
    # LOCATION: extractfacts.py:122
    chunk_prompt: "{chunk_template}\n\n=== CHUNK CONTENT ===\n{chunk}\n=== END CHUNK CONTENT ==="
    
  # Chunk processing templates
  # USED BY: digest.py - lines 181, 196 (processing document chunks)
  # LOCATION: Formats digest prompts with chunk content
  chunk_processing:
    digest_prompt: "{digest_prompt}\n\n=== DOCUMENT CHUNK ===\n{chunk}\n=== END DOCUMENT CHUNK ==="
    
  # Question and links formatting
  # USED BY: lookup.py - lines 130-133 (preparing search prompt)
  # LOCATION: Formats question with search result links
  lookup:
    question_prompt: "Question: {question}\nLinks:\n{links}"
    # USED BY: lookup.py - lines 135-138 (adding context to prompt)
    # LOCATION: Prepends context information to search prompt
    context_prompt: |
      === USER GUIDANCE (NOT facts from sources) ===
      The user wants you to consider: {context}
      IMPORTANT: This is analysis guidance only. Extract facts ONLY from the sources below.
      === END USER GUIDANCE ===
      
      {prompt}