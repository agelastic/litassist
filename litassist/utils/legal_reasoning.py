"""
Legal reasoning utilities.

This module provides functions and classes for capturing and managing
legal reasoning traces, factual hallucination detection, and content verification
used throughout LitAssist's legal analysis capabilities.
"""

import os
import re
import time
import click
from typing import List, Dict, Any, Optional

from litassist.prompts import PROMPTS
from litassist.utils.formatting import verifying_message, info_message


class LegalReasoningTrace:
    """
    Structured reasoning trace for analytical commands.

    Provides transparency in legal analysis by capturing the reasoning process
    behind conclusions in a standardized format.
    """

    def __init__(
        self,
        issue: str,
        applicable_law: str,
        application: str,
        conclusion: str,
        confidence: int,
        sources: List[str] = None,
        command: str = None,
        header: str = None,
    ):
        """
        Initialize a reasoning trace.

        Args:
            issue: The legal question or issue being analyzed
            applicable_law: The relevant legal principles, statutes, or cases
            application: How the law applies to the specific facts
            conclusion: The resulting legal conclusion
            confidence: Confidence level (0-100%)
            sources: List of legal sources cited
            command: The LitAssist command that generated this reasoning
            header: Custom header for this reasoning trace (defaults to "Overall Strategic Reasoning")
        """
        self.issue = issue
        self.applicable_law = applicable_law
        self.application = application
        self.conclusion = conclusion
        self.confidence = confidence  # No clamping - let validation catch errors
        self.sources = sources or []
        self.command = command
        self.header = header or "Overall Strategic Reasoning"
        self.timestamp = time.strftime("%Y-%m-%d %H:%M:%S")

    def to_dict(self) -> Dict[str, Any]:
        """Convert reasoning trace to dictionary format."""
        return {
            "issue": self.issue,
            "applicable_law": self.applicable_law,
            "application": self.application,
            "conclusion": self.conclusion,
            "confidence": self.confidence,
            "sources": self.sources,
            "command": self.command,
            "timestamp": self.timestamp,
        }

    def to_markdown(self) -> str:
        """Format reasoning trace as markdown."""
        sources_text = ""
        if self.sources:
            sources_text = "\n\n**Sources:**\n" + "\n".join(
                f"- {source}" for source in self.sources
            )

        return f"""## {self.header}

**Issue:** {self.issue}

**Applicable Law:** {self.applicable_law}

**Application to Facts:** {self.application}

**Conclusion:** {self.conclusion}

**Confidence:** {self.confidence}%{sources_text}

*Generated by {self.command or "LitAssist"} on {self.timestamp}*
"""

    def to_structured_text(self) -> str:
        """Format reasoning trace as structured text."""
        sources_text = ""
        if self.sources:
            sources_text = f"\nSources: {'; '.join(self.sources)}"

        return f"""## {self.header}
Issue: {self.issue}
Applicable Law: {self.applicable_law}
Application to Facts: {self.application}
Conclusion: {self.conclusion}
Confidence: {self.confidence}%{sources_text}
Generated: {self.timestamp} ({self.command or "LitAssist"})
"""


def create_reasoning_prompt(base_prompt: str, command: str) -> str:
    """
    Enhance a base prompt to include reasoning trace generation.

    Args:
        base_prompt: The original prompt for the command
        command: The LitAssist command name for context

    Returns:
        Enhanced prompt that will generate reasoning traces
    """

    # Map command types to specific reasoning headers
    reasoning_headers = {
        "brainstorm-orthodox": "Overall Orthodox Strategic Reasoning",
        "brainstorm-unorthodox": "Overall Unorthodox Strategic Reasoning",
        "brainstorm-analysis": "Strategy Selection Reasoning",
        # Default for other commands
        "default": "Overall Strategic Reasoning",
    }

    # Get the appropriate header for this command
    header = reasoning_headers.get(command, reasoning_headers["default"])

    reasoning_instruction = PROMPTS.get("reasoning.instruction").format(
        command=command, reasoning_header=header
    )
    return base_prompt + reasoning_instruction


def extract_reasoning_trace(
    content: str, command: str = None
) -> Optional[LegalReasoningTrace]:
    """
    Extract a reasoning trace from LLM output.

    Args:
        content: The LLM response content
        command: The command that generated this content

    Returns:
        LegalReasoningTrace object if found, None otherwise
    """
    # The pattern now looks for the start of the trace and captures everything
    # until the end of the content or another major header. It is non-greedy.
    # Recognizes both === separators (internal LLM processing) and markdown headers (output files)
    # Also recognizes the new specific reasoning headers for orthodox, unorthodox, and strategy selection
    trace_pattern = r"(?:=== REASONING ===|### Reasoning|## Overall (?:Orthodox |Unorthodox |)?Strategic Reasoning|## Strategy Selection Reasoning)\s*\n(.*?)(?=\n(?:===|##|###|#)|$)"
    match = re.search(trace_pattern, content, re.DOTALL | re.IGNORECASE)

    if not match:
        return None

    trace_text = match.group(1).strip()

    # More robust extraction for each component
    components = {}
    patterns = {
        "issue": r"Issue:\s*(.*?)(?=\n\s*Applicable Law:|\n\s*Application to Facts:|\n\s*Conclusion:|\n\s*Confidence:|\n\s*Sources:|\Z)",
        "applicable_law": r"Applicable Law:\s*(.*?)(?=\n\s*Application to Facts:|\n\s*Conclusion:|\n\s*Confidence:|\n\s*Sources:|\Z)",
        "application": r"Application to Facts:\s*(.*?)(?=\n\s*Conclusion:|\n\s*Confidence:|\n\s*Sources:|\Z)",
        "conclusion": r"Conclusion:\s*(.*?)(?=\n\s*Confidence:|\n\s*Sources:|\Z)",
        "confidence": r"Confidence:\s*(\d+)",
        "sources": r"Sources:\s*(.*?)(?=\n\s*Generated:|\Z)",
    }

    for key, pattern in patterns.items():
        match = re.search(pattern, trace_text, re.DOTALL | re.IGNORECASE)
        if match:
            value = match.group(1).strip()
            if key == "confidence":
                components[key] = int(value) if value.isdigit() else 50
            elif key == "sources":
                components[key] = [s.strip() for s in value.split(";") if s.strip()]
            else:
                components[key] = value

    # Check for essential components before creating the trace object
    if all(
        key in components
        for key in ["issue", "applicable_law", "application", "conclusion"]
    ):
        return LegalReasoningTrace(
            issue=components.get("issue", "N/A"),
            applicable_law=components.get("applicable_law", "N/A"),
            application=components.get("application", "N/A"),
            conclusion=components.get("conclusion", "N/A"),
            confidence=components.get("confidence", 50),
            sources=components.get("sources", []),
            command=command,
        )

    return None


def save_reasoning_trace(trace: LegalReasoningTrace, output_file: str) -> str:
    """
    Save reasoning trace to a separate file alongside the main output.

    Args:
        trace: The LegalReasoningTrace to save
        output_file: Path to the main output file

    Returns:
        Path to the saved reasoning trace file
    """
    # Create reasoning trace filename
    base_name = os.path.splitext(output_file)[0]
    trace_file = f"{base_name}_reasoning.txt"

    with open(trace_file, "w", encoding="utf-8") as f:
        f.write(trace.to_structured_text())

    return trace_file


def detect_factual_hallucinations(content: str, source_facts: str = "") -> List[str]:
    """
    Detect potential hallucinated facts in drafted content.

    Args:
        content: The drafted content to check
        source_facts: The original source facts to compare against

    Returns:
        List of potential hallucination warnings
    """
    warnings = []

    # Pattern for ages (e.g., "33 years of age", "aged 45")
    age_pattern = r"\b(\d{1,3})\s*years?\s*(?:of\s*)?(?:age|old)\b"
    ages_found = re.findall(age_pattern, content, re.IGNORECASE)
    if ages_found and source_facts:
        for age in ages_found:
            if age not in source_facts:
                warnings.append(f"Potentially hallucinated age: {age} years")

    # Pattern for specific addresses (number + street name)
    address_pattern = r"\b\d+\s+[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\s+(?:Street|St|Avenue|Ave|Road|Rd|Court|Ct|Drive|Dr|Place|Pl)\b"
    addresses_found = re.findall(address_pattern, content)
    if addresses_found and source_facts:
        for address in addresses_found:
            # Check if this exact address appears in source
            if address not in source_facts:
                warnings.append(f"Potentially hallucinated address: {address}")

    # Pattern for bank/credit card numbers
    account_pattern = r"(?:account|a/c|card).*?(?:ending|number|no\.?)\s*(?:in\s*)?[-:\s]*(\d{4,}|\*+\d{4}|-\d{4})"
    accounts_found = re.findall(account_pattern, content, re.IGNORECASE)
    if accounts_found:
        for account in accounts_found:
            if source_facts and account not in source_facts:
                warnings.append(
                    f"Potentially hallucinated account/card number: {account}"
                )

    # Pattern for specific exhibit numbers (e.g., "VO-1", "Exhibit 23")
    exhibit_pattern = r"(?:exhibit|annexure)\s*(?:marked\s*)?([A-Z]{1,3}-?\d+|\d+)"
    exhibits_found = re.findall(exhibit_pattern, content, re.IGNORECASE)
    if exhibits_found:
        warnings.append(
            f"Specific exhibit references found: {', '.join(set(exhibits_found))}. Consider using generic placeholders like [EXHIBIT A]"
        )

    # Pattern for document/reference numbers (e.g., "Order No. 12345", "Cheque No. 67890")
    ref_pattern = r"(?:order|cheque|check|reference|ref|invoice|receipt)\s*(?:no\.?|number)\s*[:\s]*(\d{4,})"
    refs_found = re.findall(ref_pattern, content, re.IGNORECASE)
    if refs_found and source_facts:
        for ref in refs_found:
            if ref not in source_facts:
                warnings.append(f"Potentially hallucinated reference number: {ref}")

    # Check for suspiciously specific dates not in source
    date_pattern = r"\b(\d{1,2})\s+(?:January|February|March|April|May|June|July|August|September|October|November|December)\s+(\d{4})\b"
    dates_found = re.findall(date_pattern, content, re.IGNORECASE)
    if dates_found and source_facts:
        for date in dates_found:
            date_str = f"{date[0]} {date[1]}"
            # Very basic check - could be improved
            if date_str not in source_facts and date[0] not in source_facts:
                warnings.append(f"Potentially hallucinated specific date: {date_str}")

    return warnings


def verify_content_if_needed(
    client: Any,
    content: str,
    command_name: str,
    verify_flag: bool = False,
    citation_already_verified: bool = False,
) -> tuple[str, bool]:
    """
    Handle verification and citation validation.

    Args:
        client: LLMClient instance
        content: Content to verify
        command_name: Name of the command (for context)
        verify_flag: Whether user explicitly requested verification
        citation_already_verified: Whether citation verification was already performed

    Returns:
        Tuple of (possibly modified content, whether verification was performed)
    """
    # Mandatory verification chain for high-risk commands
    if command_name in ["extractfacts", "strategy", "draft"]:
        from litassist.verification_chain import run_verification_chain

        verified_content, results = run_verification_chain(content, command_name)
        if results.get("llm", {}).get("corrections_made"):
            return verified_content, True
        # If no corrections were made, return original content
        return content, False

    # Check if auto-verification is needed
    auto_verify = client.should_auto_verify(content, command_name)
    needs_verification = verify_flag or auto_verify

    # Inform user about verification status (suppress during tests)
    if not os.environ.get("PYTEST_CURRENT_TEST"):
        if verify_flag and auto_verify:
            click.echo(
                verifying_message(
                    "Running verification (--verify flag + auto-verification triggered)"
                )
            )
        elif verify_flag:
            click.echo(
                verifying_message("Running verification (--verify flag enabled)")
            )
        elif auto_verify:
            click.echo(
                verifying_message(
                    "Running auto-verification (high-risk content detected)"
                )
            )
        else:
            click.echo(info_message("No verification performed"))

    if needs_verification:
        try:
            # Standard verification for remaining commands
            correction = client.verify(content)

            # Handle tuple return from new verify methods
            if isinstance(correction, tuple):
                correction = correction[0]

            if correction.strip() and not correction.lower().startswith(
                "no corrections needed"
            ):
                content = (
                    content
                    + f"\n\n--- {command_name.title()} Review ---\n"
                    + correction
                )

            # Run citation validation (skip if already verified)
            if not citation_already_verified:
                citation_issues = client.validate_citations(content)
                if citation_issues:
                    content += "\n\n--- Citation Warnings ---\n" + "\n".join(
                        citation_issues
                    )

        except Exception as e:
            raise click.ClickException(f"Verification error during {command_name}: {e}")

    return content, needs_verification
